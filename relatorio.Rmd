---
title: ''
author: ''
date: ''
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Árvore de decisão

A árvore de decisão envolve *estratificar* ou *segmentar* o espaço das preditoras em várias regiões simples. Para fazer uma previsão para uma determinada observação, normalmente usamos a média ou o valor da resposta modal para as observações de treinamento na região à qual ela pertence. Como o conjunto de regras de divisão usadas para segmentar o espaço do preditor pode ser resumido em uma árvore, esses tipos de abordagens são conhecidos como métodos de árvore de decisão. Os métodos baseados em árvores são simples e úteis para interpretação. No entanto, eles normalmente não são competitivos com as melhores abordagens de aprendizado supervisionado em termos de precisão de previsão. Portanto, neste projeto também apresentamos *bagging* e *florestas aleatórias*. Cada uma dessas abordagens envolve a produção de várias árvores que são então combinadas para produzir uma única previsão. Veremos que combinar um grande número de árvores muitas vezes pode resultar em melhorias dramáticas na precisão da previsão, às custas de alguma perda na interpretação.

Discutimos agora o processo de construção de uma árvore de regressão. Grosso modo, são duas etapas.

1.  Dividimos o espaço das preditoras --- isto é, o conjunto de valores possíveis para $X_1, X_2,…,X_p$ --- em $J$ regiões distintas e não sobrepostas, $R_1, R_2,…,R_J$.

2.  Para cada observação que cai na região $R_j$, fazemos a mesma previsão, que é simplesmente a média dos valores da variável resposta para as observações de treinamento em $R_j$.

Para exemplificar, veja a figura abaixo. Temos as preditoras $X_1$ = Years e $X_2$ = Hits para uma determinada variável resposta. No gráfico à esquerda, dividimos o espaço das preditoras e 3 regiões distintas e não sobrepostas, $R_1, R_2, R_3$ (Passo 1). No gráfico à direita, temos a representação das regiões no formato de árvore, onde cada região contém a média dos valores da variável resposta (Passo 2). Por exemplo, se uma nova observação tiver Years \< 4.5, a prevemos como 5.11.

![](images/tree-plot.png)

Como construímos as regiões $R_1,…,R_J$? Em teoria, as regiões poderiam ter qualquer forma. No entanto, optamos por dividir o espaço das preditoras em retângulos de alta dimensão, ou caixas, para simplificar e facilitar a interpretação do modelo preditivo resultante. O objetivo é encontrar caixas $R_1,…,R_J$ que minimizem o RSS, dado por

$$\sum_{j=1}^{J} \sum_{i \in R_{j}}\left(y_{i}-\hat{y}_{R_{j}}\right)^{2},$$

onde $\hat y_{R_j}$ é a resposta média para as observações de treinamento dentro da j-ésima caixa. Infelizmente, é computacionalmente inviável considerar todas as partições possíveis do espaço de features em $J$ caixas. Por esse motivo, adotamos uma abordagem *gananciosa de cima para baixo*, conhecida como *divisão binária recursiva*. A abordagem de divisão binária recursiva é *de cima para baixo* porque começa no topo da árvore (no ponto em que todas as observações pertencem a uma única região) e então divide sucessivamente o espaço das preditoras; cada divisão é indicada através de dois novos ramos mais abaixo na árvore. É *gananciosa* porque em cada etapa do processo de construção da árvore, a *melhor* divisão é feita naquela etapa específica, em vez de olhar para frente e escolher uma divisão que levará a uma melhor árvore em alguma etapa futura.

Para realizar a divisão binária recursiva, primeiro selecionamos o preditor $X_j$ e o ponto de corte $s$ de modo que dividir o espaço das preditoras nas regiões $\{X|X_j < s\}$ e $\{X|X_j ≥ s\}$ leva à maior redução possível em RSS. Ou seja, consideramos todos as preditoras $X_1,…,X_p$ e todos os valores possíveis do ponto de corte $s$ para cada um das preditoras e, em seguida, escolhemos a preditora e o ponto de corte de modo que a árvore resultante tenha o RSS mais baixo.

Em seguida, repetimos o processo, procurando o melhor preditor e o melhor ponto de corte para dividir ainda mais os dados de modo a minimizar o RSS dentro de cada uma das regiões resultantes. No entanto, desta vez, em vez de dividir todo o espaço do preditor, dividimos uma das duas regiões identificadas anteriormente. Agora temos três regiões. Novamente, procuramos dividir ainda mais uma dessas três regiões, de modo a minimizar o RSS. O processo continua até que um critério de parada seja alcançado; por exemplo, podemos continuar até que nenhuma região contenha mais de cinco observações.

Uma vez criadas as regiões $R_1,…,R_J$, prevemos a resposta para uma determinada observação de teste usando a média das observações de treinamento na região à qual essa observação de teste pertence.

Um exemplo de cinco regiões dessa abordagem é mostrado na Figura abaixo.

![](images/tree-example.png)

## Limitações

O processo descrito acima pode produzir boas previsões no conjunto de treinamento, mas é provável que tenha overfit, levando a um desempenho ruim no conjunto de teste. Isso ocorre porque a árvore resultante pode ser muito complexa. Uma árvore menor com menos divisões (ou seja, menos regiões $R1,…,RJ$) pode levar a menor variância e melhor interpretação ao custo de um pouco de viés. Uma alternativa possível para o processo descrito acima é aplicar uma técnica de regularização chamada *Tree Pruning*. Não vamos entrar em detalhes sobre como essa técnica funciona. Para mais detalhes consulte o livro na bibliografia.

## Simulação

Vamos usar um banco de dados com informações das músicas do spotify. Os dados contêm 50.000 músicas. Vamos construir árvores com o método de podas de árvore (Tree Pruning).

```{r}
library(tidyverse)
```

```{r}
spotify = read.csv("data/music_genre.csv")
```

```{r}
spotify[spotify |> duplicated(),]
```

```{r}
# Remove linhas duplicadas. Que nesse caso é equivalente às linhas nulas
spotify = spotify[!is.na(spotify$instance_id),]
```

```{r}
# Remove colunas irrelevantes e colunas categóricas para agilizar o tempo de treino
spotify = spotify |> select(-instance_id, -artist_name, -track_name, -obtained_date, -key, -mode, -music_genre)
```

```{r}
spotify$tempo = ifelse(spotify$tempo == '?', NA, spotify$tempo) |> as.numeric()
```

```{r}
media_tempo = mean(spotify$tempo, na.rm = TRUE)
spotify$tempo = ifelse(is.na(spotify$tempo), media_tempo, spotify$tempo)
```

```{r}
spotify$duration_ms = ifelse(spotify$duration_ms == -1, NA, spotify$duration_ms)
media_duration = mean(spotify$duration_ms, na.rm = TRUE)
spotify$duration_ms = ifelse(is.na(spotify$duration_ms), media_duration, spotify$duration_ms)
```

```{r}
library(caret)
library(ggthemes)
library(showtext)
```

```{r}
set.seed(123)
model_dt = train(
  popularity ~ ., data = spotify, 
  method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10)
```

```{r}
model_dt$bestTune
```

```{r}
font_add_google('Poppins', 'myfont')
showtext_auto()
```

```{r}
model_dt$results |> 
  ggplot(aes(x = cp, y = RMSE)) +
  geom_line(color = "#0099f9", size = 0.5) +
  geom_point(color = "#0099f9", size = 2, shape = 21, fill = "white", stroke = 2) +
  labs(title = "Árvore de decisão com poda", subtitle = "Melhor árvore: cp = 0.00412867, profundidade = 7") +
  theme_hc() +
  theme(axis.title = element_text(family = 'myfont'),
        axis.text = element_text(family = 'myfont'),
        plot.title = element_text(family = 'myfont', face = 'bold', size = 18),
        plot.subtitle = element_text(family = 'myfont', color = "#424242"))
```

```{r}
rpart.plot::rpart.plot(model_dt$finalModel, type = 5)
```

# Ensemble

Um método *ensemble* é uma abordagem que combina muitos modelos simples de "blocos de construção" para obter um modelo único e potencialmente muito poderoso. Esses modelos de blocos de construção simples às vezes são conhecidos como *weak learners*, pois podem levar a previsões medíocres por si só.

Discutiremos agora bagging e florestas aleatórias. Esses são métodos ensemble para os quais o bloco de construção simples é uma árvore de regressão.

# Bagging

O bootstrap é uma ideia extremamente poderosa. É usado em muitas situações em que é difícil ou mesmo impossível calcular diretamente o desvio padrão de uma quantidade de interesse. Vemos aqui que o bootstrap pode ser usado em um contexto completamente diferente, a fim de melhorar métodos de aprendizado estatístico, como árvores de decisão.

As árvores de decisão sofrem de alta variância. Isso significa que, se dividirmos os dados de treinamento em duas partes aleatoriamente e ajustarmos uma árvore de decisão a ambas as metades, os resultados obtidos poderão ser bem diferentes. Em contraste, um procedimento com baixa variância produzirá resultados semelhantes se aplicado repetidamente a conjuntos de dados distintos; a regressão linear tende a ter baixa variância, se a razão de $n$ para $p$ for moderadamente grande. O *bootstrap aggregation*, ou *bagging*, é um procedimento de propósito geral para reduzir a variação de um método de aprendizado estatístico; nós o introduzimos aqui porque é particularmente útil e frequentemente usado no contexto de árvores de decisão.

Lembre-se que dado um conjunto de $n$ observações independentes $Z_1,…,Z_n$, cada uma com variância $\sigma^2$, a variância da média $\bar Z$ das observações é dada por $\sigma^2/n$. Em outras palavras, a média de um conjunto de observações reduz a variância. Portanto, uma maneira natural de reduzir a variância e aumentar a precisão do conjunto de teste de um método de aprendizado estatístico é pegar muitos conjuntos de treinamento da população, construir um modelo de previsão separado usando cada conjunto de treinamento e calcular a média das previsões resultantes. Em outras palavras, poderíamos calcular $\hat f^1(x), \hat f^2(x),…, \hat f^B(x)$ usando $B$ conjuntos de treinamento separados e fazer a média deles para obter um único modelo de aprendizado estatístico de baixa variância, dado por

$$
\hat{f}_{\mathrm{avg}}(x)=\frac{1}{B} \sum_{b=1}^{B} \hat{f}^{b}(x).
$$

Claro, isso não é prático porque geralmente não temos acesso a vários conjuntos de treinamento. Em vez disso, podemos aplicar o bootstrap, obtendo amostras repetidas do (único) conjunto de dados de treinamento. Nesta abordagem, geramos $B$ diferentes conjuntos de dados de treinamento por bootstrap. Em seguida, treinamos nosso método no b-ésimo conjunto de treinamento por bootstrap para obter $\hat f^{∗b}(x)$ e, finalmente, calculamos a média de todas as previsões, para obter

$$
\hat{f}_{\mathrm{bag}}(x)=\frac{1}{B} \sum_{b=1}^{B} \hat{f}^{*b}(x).
$$

Isso é chamado de bagging.

## Importância de variáveis

Como discutimos, o bagging normalmente resulta em maior precisão em relação à previsão usando uma única árvore. Infelizmente, no entanto, pode ser difícil interpretar o modelo resultante. Lembre-se de que uma das vantagens das árvores de decisão é o diagrama atraente e de fácil interpretação que resulta. No entanto, quando agregamos um grande número de árvores, não é mais possível representar o procedimento de aprendizado estatístico resultante usando uma única árvore e não fica mais claro quais variáveis ​​são mais importantes para o procedimento. Assim, o bagging melhora a precisão da previsão em detrimento da interpretabilidade.

Embora a coleção de árvores agregadas seja muito mais difícil de interpretar do que uma única árvore, pode-se obter um resumo geral da importância de cada preditor usando o RSS (para bagging usando árvores de regressão). No caso do bagging usando árvores de regressão, podemos registrar a quantidade total que o RSS é diminuído devido a divisões em um determinado preditor, com média de todas as árvores B. Um valor grande indica um preditor importante.

# Floresta aleatória

*Florestas aleatórias* fornecem uma melhoria em relação às árvores do bagging por meio de um pequeno ajuste que *descorrelaciona* as árvores. Assim como no bagging, construímos uma série de árvores de decisão em amostras de treinamento bootstrap. Mas ao construir essas árvores de decisão, cada vez que uma divisão em uma árvore é considerada, *uma amostra aleatória de m preditores* é escolhida como candidatos a divisão do conjunto completo de *p* preditores. A divisão pode usar apenas um desses *m* preditores. Uma nova amostra de *m* preditores é coletada em cada divisão e, normalmente, escolhemos $m \approx \sqrt p$ -- ou seja, o número de preditores considerados em cada divisão é aproximadamente igual à raiz quadrada do número total de predito.

Em outras palavras, ao construir uma floresta aleatória, a cada divisão na árvore, o algoritmo *não pode sequer considerar* a maioria dos preditores disponíveis. Isso pode parecer loucura, mas tem uma lógica inteligente. Suponha que haja um preditor muito forte no conjunto de dados, juntamente com vários outros preditores moderadamente fortes. Então, na coleção de árvores do bagging, a maioria ou todas as árvores usarão esse forte preditor na divisão superior. Consequentemente, todas as árvores do bagging serão bastante semelhantes entre si. Portanto, as previsões das árvores do bagging serão altamente correlacionadas. Infelizmente, a média de muitas quantidades altamente correlacionadas não leva a uma redução tão grande na variância quanto a média de muitas quantidades não correlacionadas. Em particular, isso significa que o bagging não levará a uma redução substancial na variância em relação a uma única árvore nesse cenário.

As florestas aleatórias superam esse problema forçando cada divisão a considerar apenas um subconjunto dos preditores. Portanto, em média $(p − m)/p$ das divisões nem mesmo considerará o preditor forte e, portanto, outros preditores terão mais chances. Podemos pensar nesse processo como *descorrelacionar* as árvores, tornando a média das árvores resultantes menos variável e, portanto, mais confiável.

A principal diferença entre bagging e florestas aleatórias é a escolha do tamanho do subconjunto do preditor *m*. Por exemplo, se uma floresta aleatória é construída usando $m = p$, isso equivale simplesmente ao bagging. Usar um pequeno valor de *m* na construção de uma floresta aleatória normalmente será útil quando tivermos um grande número de preditores correlacionados. Assim como acontece com o bagging, as florestas aleatórias não serão superajustadas se aumentarmos $B$, então, na prática, usamos um valor de $B$ suficientemente grande para que a taxa de erro se estabeleça.
